{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "679Lmwt3l1Bk"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks \n",
    "## Session 24a: Lecture\n",
    "\n",
    "##  Convolutional Neural Network (CNN)\n",
    "- Dropout\n",
    "- Flowers\n",
    "- Dataset From directory\n",
    "\n",
    "<img src='../../images/prasami_color_tutorials_small.png' style = 'width:400px;' alt=\"By Pramod Sharma : pramod.sharma@prasami.com\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAve6DCL4JH4"
   },
   "outputs": [],
   "source": [
    "###-----------------\n",
    "### Import Libraries\n",
    "###-----------------\n",
    "\n",
    "import os\n",
    "#import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----------------------\n",
    "### Some basic parameters\n",
    "###----------------------\n",
    "\n",
    "\n",
    "inpDir = '../../input' # location where input data is stored\n",
    "outDir = '../output' # location to store outputs\n",
    "modelDir = '../models'\n",
    "subDir = 'flower_photos'\n",
    "altName = 'cnn_base'\n",
    "\n",
    "RANDOM_STATE = 24 # for initialization ----- REMEMBER: to remove at the time of promotion to production\n",
    "tf.random.set_seed(RANDOM_STATE) # setting for Tensorflow as well\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "ALPHA = 0.001\n",
    "EPOCHS = 50 # number of cycles to run\n",
    "PATIENCE = 20\n",
    "LR_PATIENCE = 10\n",
    "FACTOR_LR = 0.5\n",
    "BATCH_SIZE = 32 # inline of Training Rows being 60000\n",
    "IMG_HEIGHT = 190\n",
    "IMG_WIDTH = 190\n",
    "\n",
    "\n",
    "# Set parameters for decoration of plots\n",
    "params = {'legend.fontsize' : 'large',\n",
    "          'figure.figsize'  : (15,10),\n",
    "          'axes.labelsize'  : 'x-large',\n",
    "          'axes.titlesize'  :'x-large',\n",
    "          'xtick.labelsize' :'large',\n",
    "          'ytick.labelsize' :'large',\n",
    "         }\n",
    "\n",
    "CMAP = plt.cm.coolwarm\n",
    "\n",
    "plt.rcParams.update(params) # update rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Hygiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAve6DCL4JH4"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_verify_dir(_path : str):\n",
    "    '''\n",
    "    Arg:\n",
    "        path: path to verify the directory\n",
    "    returns:\n",
    "        create dir if it does not exists\n",
    "    '''\n",
    "    if os.path.exists(_path): # check if the path exists. Maybe a file or a folder\n",
    "        \n",
    "        print(_path, ' exists') # advised the user\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        os.makedirs(_path) # create the path\n",
    "        \n",
    "        print(\"Created folder : \", _path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-----------------------------------\n",
    "### Function to plot Loss Curve\n",
    "###-----------------------------------\n",
    "\n",
    "def fn_plot_tf_hist(hist_df : pd.DataFrame):\n",
    "    '''\n",
    "    Args:\n",
    "      hist_df : pandas Dataframe with four columns\n",
    "                For 'x' values, we will use index\n",
    "    '''\n",
    "    fig, axes = plt.subplots(1,2 , figsize = (15,6))\n",
    "\n",
    "    # properties  matplotlib.patch.Patch \n",
    "    props = dict(boxstyle='round', facecolor='aqua', alpha=0.4)\n",
    "    facecolor = 'cyan'\n",
    "    fontsize=12\n",
    "    \n",
    "    # Get columns by index to eliminate any column naming error\n",
    "    y1 = hist_df.columns[0]\n",
    "    y2 = hist_df.columns[1]\n",
    "    y3 = hist_df.columns[2]\n",
    "    y4 = hist_df.columns[3]\n",
    "\n",
    "    # Where was min loss\n",
    "    best = hist_df[hist_df[y3] == hist_df[y3].min()]\n",
    "    \n",
    "    ax = axes[0]\n",
    "\n",
    "    hist_df.plot(y = [y1,y3], ax = ax, colormap=CMAP)\n",
    "\n",
    "\n",
    "    # little beautification\n",
    "    txtFmt = \"Loss: \\n  train: {:6.4f}\\n   test: {:6.4f}\"\n",
    "    txtstr = txtFmt.format(hist_df.iloc[-1][y1],\n",
    "                           hist_df.iloc[-1][y3]) #text to plot\n",
    "    \n",
    "    # place a text box in upper middle in axes coords\n",
    "    ax.text(0.3, 0.95, txtstr, transform=ax.transAxes, fontsize=fontsize,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "    # Mark arrow at lowest\n",
    "    ax.annotate(f'Min: {best[y3].to_numpy()[0]:6.4f}', # text to print\n",
    "                xy=(best.index.to_numpy(), best[y3].to_numpy()[0]), # Arrow start\n",
    "                xytext=(best.index.to_numpy()-1, best[y3].to_numpy()[0]), # location of text \n",
    "                fontsize=fontsize, va='bottom', ha='right',bbox=props, # beautification of text\n",
    "                arrowprops=dict(facecolor=facecolor, shrink=0.05)) # arrow\n",
    "\n",
    "    # Draw vertical line at best value\n",
    "    ax.axvline(x = best.index.to_numpy(), color = 'green', linestyle='-.', lw = 3);\n",
    "\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(y1.capitalize())\n",
    "    ax.set_title('Errors')\n",
    "    ax.grid();\n",
    "    ax.legend(loc = 'upper left') # model legend to upper left\n",
    "\n",
    "    ax = axes[1]\n",
    "\n",
    "    hist_df.plot( y = [y2, y4], ax = ax, colormap=CMAP)\n",
    "    \n",
    "    # little beautification\n",
    "    txtFmt = \"Accuracy: \\n  train: {:6.4f}\\n  test:  {:6.4f}\"\n",
    "    txtstr = txtFmt.format(hist_df.iloc[-1][y2],\n",
    "                           hist_df.iloc[-1][y4]) #text to plot\n",
    "\n",
    "    # place a text box in upper middle in axes coords\n",
    "    ax.text(0.3, 0.2, txtstr, transform=ax.transAxes, fontsize=fontsize,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "    # Mark arrow at lowest\n",
    "    ax.annotate(f'Best: {best[y4].to_numpy()[0]:6.4f}', # text to print\n",
    "                xy=(best.index.to_numpy(), best[y4].to_numpy()[0]), # Arrow start\n",
    "                xytext=(best.index.to_numpy()-1, best[y4].to_numpy()[0]), # location of text \n",
    "                fontsize=fontsize, va='bottom', ha='right',bbox=props, # beautification of text\n",
    "                arrowprops=dict(facecolor=facecolor, shrink=0.05)) # arrow\n",
    "    \n",
    "    \n",
    "    # Draw vertical line at best value\n",
    "    ax.axvline(x = best.index.to_numpy(), color = 'green', linestyle='-.', lw = 3);\n",
    "\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(y2.capitalize())\n",
    "    ax.grid()\n",
    "    ax.legend(loc = 'lower left')\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_plot_label(tr_ds, ts_ds):\n",
    "    \n",
    "    plt.figure(figsize = (15,5)) # instantiate the figure\n",
    "    \n",
    "    plt.subplot(1,2,1) # first out of 2\n",
    "\n",
    "    train_labels = tf.concat([lbl for img, lbl in tr_ds], axis = 0).numpy() # get the labels\n",
    "\n",
    "    unique, _, counts = tf.unique_with_counts(train_labels) # get counts\n",
    "\n",
    "    plt.bar(range(len(unique)), counts, align='center', color = 'DarkBlue') # barplot the counts\n",
    "\n",
    "    plt.xticks(range(len(unique)), class_names)\n",
    "\n",
    "    plt.title('Training Set')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    \n",
    "    test_labels = tf.concat([lbl for img, lbl in ts_ds], axis = 0).numpy()\n",
    "\n",
    "    unique, _, counts = tf.unique_with_counts(test_labels)\n",
    "\n",
    "    plt.bar(range(len(unique)), counts, align='center', color = 'Orange')\n",
    "\n",
    "    plt.xticks(range(len(unique)), class_names)\n",
    "\n",
    "    plt.title('Test Set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = os.path.join(inpDir, subDir, 'fashion-mnist_train.csv')\n",
    "test_filename = os.path.join(inpDir, subDir, 'fashion-mnist_test.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_filename, header = 0)\n",
    "test_df = pd.read_csv(test_filename, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_plot_label(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                   fname='flower_photos',\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)'''\n",
    "\n",
    "\n",
    "data_dir = os.path.join(inpDir, subDir)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data\n",
    "train_ds =tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, # path the the data directory\n",
    "    validation_split=TEST_SIZE, # what ratio of validation data\n",
    "    subset='training', # purpose\n",
    "    seed=RANDOM_STATE, \n",
    "    image_size=[IMG_HEIGHT, IMG_WIDTH], ## @@@ WHAT!\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "# test data\n",
    "test_ds =tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, # path the the data directory\n",
    "    validation_split=TEST_SIZE, # what ratio of validation data\n",
    "    subset='validation', # purpose\n",
    "    seed=RANDOM_STATE, \n",
    "    image_size=[IMG_HEIGHT, IMG_WIDTH], ## @@@ WHAT!\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is it picking class names\n",
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range (BATCH_SIZE):\n",
    "        plt.subplot(int(BATCH_SIZE/8), 8, i +1)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i].numpy().astype('uint8'))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "for images, labels in test_ds.take(1): # get me one batch\n",
    "    \n",
    "    for i in range (BATCH_SIZE): # loop over batch\n",
    "        \n",
    "        plt.subplot(int(BATCH_SIZE/8), 8, i +1) # access the axis\n",
    "        \n",
    "        plt.grid(False) # no to grid\n",
    "        \n",
    "        plt.imshow(images[i].numpy().astype('uint8')) # show image convert to numpy and int\n",
    "        \n",
    "        plt.title(class_names[labels[i]])\n",
    "        \n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_plot_label(train_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer =tf.keras.layers.RandomZoom(height_factor=(-0.2, -0.2), \n",
    "                                  width_factor=(-0.2, -0.2) )\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "img_num = 3\n",
    "\n",
    "for images, labels in test_ds.take(1): # get me one batch\n",
    "    \n",
    "    out_images = layer(images)\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Original')\n",
    "    plt.imshow(images[img_num].numpy().astype('uint8'))\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Zoomed')\n",
    "    plt.imshow(out_images[img_num].numpy().astype('uint8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "\n",
    "model =  tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Rescaling(1/255.)) # convert between 0 and 1\n",
    "\n",
    "\n",
    "###-------\n",
    "### Set I\n",
    "###--------\n",
    "model.add(tf.keras.layers.Conv2D(8, (3,3), activation='relu')) # 188 x 188 x 8\n",
    "model.add(tf.keras.layers.MaxPool2D(2,2)) # 94 x 94 x 8\n",
    "###-------\n",
    "### Set II\n",
    "###--------\n",
    "model.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu')) # 92 x 92 x 16\n",
    "model.add(tf.keras.layers.MaxPool2D(2,2)) # 46 x 46 x 16\n",
    "###-------\n",
    "### Set III\n",
    "###--------\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu')) # 44 x 44 x 32\n",
    "model.add(tf.keras.layers.MaxPool2D(2,2)) # 22 x 22 x 32\n",
    "###-------\n",
    "### Set IV\n",
    "###--------\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu')) # 20 x 20 x 128\n",
    "model.add(tf.keras.layers.MaxPool2D(2,2)) # 10 x 10 x 64\n",
    "\n",
    "\n",
    "###-------\n",
    "### Set V\n",
    "###--------\n",
    "model.add(tf.keras.layers.Conv2D(128, (3,3), activation='relu')) # 8 x 8 x 128\n",
    "model.add(tf.keras.layers.MaxPool2D(2,2)) # 4 x 4 x 128\n",
    "\n",
    "###-------\n",
    "### Set VI\n",
    "###--------\n",
    "model.add(tf.keras.layers.Conv2D(256, (3,3), activation='relu')) # 2 x 2 x 256\n",
    "\n",
    "###-------\n",
    "### Head Starts\n",
    "###--------\n",
    "model.add(tf.keras.layers.Flatten()) # Flatten\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu')) # Dense 1\n",
    "\n",
    "model.add(tf.keras.layers.Dense(5)) # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.Adam(learning_rate = ALPHA)\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optim, loss = loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    patience=PATIENCE,\n",
    "    mode='auto',\n",
    "    baseline =None,\n",
    "    restore_best_weights=True,\n",
    "    verbose = 1)\n",
    "\n",
    "lr_decay = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=FACTOR_LR,\n",
    "    patience=LR_PATIENCE,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "# define model file path\n",
    "modelFile = os.path.join(modelDir, subDir, altName)\n",
    "\n",
    "# define checkpoint callback\n",
    "model_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    modelFile,\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 1,\n",
    "    save_best_only = True,\n",
    "    save_weights_only = True,\n",
    "    mode = 'auto',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, validation_data=test_ds, \n",
    "                    epochs=EPOCHS, \n",
    "                    verbose=1, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    callbacks=[early_stopping_callback, lr_decay, model_callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(history.history)\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_plot_tf_hist(res_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKgyC5K_4O0d"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtyDF0MKUcM7"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = tf.concat([y for x, y in test_ds], axis=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(test_ds)\n",
    "\n",
    "y_pred = yhat.argmax(axis = 1)\n",
    "\n",
    "print(f'Accuracy score on Test Data : {accuracy_score(y_test, y_pred) : .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|| |Predicted| class\n",
    "|:-|:-|:-|:-|\n",
    "| | |P|N|\n",
    "Actual|P|TP|FN\n",
    "class|N|FP|TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMAP = plt.cm.Blues\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                       display_labels=class_names)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "\n",
    "disp.plot(ax = ax, cmap=CMAP, colorbar=False, xticks_rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in test_ds.take(5):\n",
    "\n",
    "    yhat =  model.predict(images, verbose= 0)\n",
    "\n",
    "    y_pred = yhat.argmax( axis = 1 )\n",
    "    \n",
    "    fig, axes = plt.subplots(BATCH_SIZE//8 , 8)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    \n",
    "    for i in range( BATCH_SIZE):\n",
    "\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images[i].numpy().astype('uint8'))\n",
    "        #ax.set_title(f'{class_names[labels[i].numpy()]}')\n",
    "        ax.set_title(f'{class_names[y_pred[i]]}')\n",
    "        ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
